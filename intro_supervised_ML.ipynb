{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a11c423b",
   "metadata": {},
   "source": [
    "## Introduction to Supervised Machine Learning\n",
    "**Instructor:** Lisa-Marie Rolli, Volkamer Lab, Saarland University (lisa-marie.rolli@uni-saarland.de)\n",
    "\n",
    "\n",
    "**Workshop date:** 13th January 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a734988a",
   "metadata": {},
   "source": [
    "Machine learning (ML) is a research area in computer science, where algorithms are developed to learn from data. Generally, ML can be subdivided into four major realms: (i) supervised learning, (ii) unsupervised learning, (iii) semi-supervised learning, and (iv) reinforcement learning. In this notebook, we focus on supervised ML. In supervised ML, an algorithm learns to predict a specific *response* (e.g., toxicity) for a sample (e.g., compound) based on *features* of the sample (e.g., physicochemical propteries). The learning is based on the assumption that there is a functional relationship between the features and the response, which we can approximate. There exist a plethora of different algorithms, which mainly differ in their assumptions about the true relationship and their learning algorithm, i.e., how they approximate the true function. In this tutorial we will start with linear regression, which assumes a linear relationship between the features and the response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e6663a",
   "metadata": {},
   "source": [
    "### Data\n",
    "As mentioned above, the dataset must consist of *features*, i.e., descriptors of the samples, and a *response*, i.e., a measurement that we want to predict. The goal is to learn a relationship between the features and the response for a given *training set* of samples so that we can later predict for *unseen* samples. In particular, we always separate a hold out *test set*, which is used to evaluate how well our model predicts for samples that it has not seen during training.\n",
    "\n",
    "The first step in each ML pipeline is understanding the data. Thus, we load a toy dataset with diabetes data and look at the description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098ad804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !pip install rdkit\n",
    "    !wget https://raw.githubusercontent.com/volkamerlab/Programming4RADAR/refs/heads/main/Example_Data/continuous_response.tsv\n",
    "    !wget https://raw.githubusercontent.com/volkamerlab/Programming4RADAR/refs/heads/main/Example_Data/smiles.tsv\n",
    "    !wget https://raw.githubusercontent.com/volkamerlab/Programming4RADAR/refs/heads/main/Example_Data/test.txt\n",
    "    !wget https://raw.githubusercontent.com/volkamerlab/Programming4RADAR/refs/heads/main/Example_Data/train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0254fbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw, Descriptors, rdMolDescriptors\n",
    "from rdkit.Chem import PandasTools\n",
    "import copy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7709f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not IN_COLAB:\n",
    "    smiles_df = pd.read_csv('Example_Data/smiles.tsv', sep = '\\t', index_col = 0)\n",
    "else:\n",
    "    smiles_df = pd.read_csv('smiles.tsv', sep = '\\t', index_col = 0)\n",
    "smiles_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d8dc0d",
   "metadata": {},
   "source": [
    "Most ML models are not able to directly process text, e.g., SMILES strings. Therefore, we calculate numerical descriptors that are easier for the model to understand. One of the most simple representations are physicochemical properties that we can calculate using RDKit. RDKit is a library that can (among other things) read SMILES and store them as a molecule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6a1f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_caffeine = \"CN1C=NC2=C1C(=O)N(C(=O)N2C)C\"\n",
    "caffeine = Chem.MolFromSmiles(smiles_caffeine)\n",
    "Draw.MolsToImage([caffeine])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463057af",
   "metadata": {},
   "source": [
    "After reading the SMILES, we can also caluclate different physiochemical properties of the molcule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed30f6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MolWt: {Descriptors.MolWt(caffeine)}\")\n",
    "print(f\"logP: {Descriptors.MolLogP(caffeine)}\")\n",
    "print(f\"Num HBA: {rdMolDescriptors.CalcNumHBA(caffeine)}\")\n",
    "print(f\"Num HBD: {rdMolDescriptors.CalcNumHBD(caffeine)}\")\n",
    "print(f\"Num rotable bonds (RB): {rdMolDescriptors.CalcNumRotatableBonds(caffeine)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c367f27",
   "metadata": {},
   "source": [
    "Now, we want to calculate some physicochemical properties for all molecules in our ```smiles_df``` data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cc72d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure that molecules are displayed in dataframe\n",
    "PandasTools.RenderImagesInAllColumns = True\n",
    "\n",
    "PandasTools.AddMoleculeColumnToFrame(smiles_df, \"canonical SMILES\", molCol='molecule')\n",
    "smiles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2206d037",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_df[\"mol_wt\"] = smiles_df[\n",
    "    \"molecule\"\n",
    "].apply(Descriptors.MolWt)\n",
    "# if we have missing values, we remove the molecules\n",
    "smiles_df.dropna(inplace=True)\n",
    "smiles_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5110d706",
   "metadata": {},
   "source": [
    "Now, we load the target, i.e., the continuous values, that we want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793a5f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not IN_COLAB:\n",
    "    response_df = pd.read_csv('Example_Data/continuous_response.tsv', sep = '\\t', index_col = 0)\n",
    "else:\n",
    "    response_df = pd.read_csv('continuous_response.tsv', sep = '\\t', index_col = 0)\n",
    "response_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b822f39",
   "metadata": {},
   "source": [
    "As not all molecules are necessarily tested in all assays, we now only take the intersection of molecules with available properties and response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81940576",
   "metadata": {},
   "outputs": [],
   "source": [
    "considered_mols = list(set(smiles_df.index).intersection(set(response_df.index)))\n",
    "X = smiles_df.loc[considered_mols, ['mol_wt']]\n",
    "y = response_df.loc[considered_mols]\n",
    "print(f'We have {len(considered_mols)} molecules in our dataset.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07f087b",
   "metadata": {},
   "source": [
    "Now, we can have a look at the response plotted with respect to the different features (physicochemical properties) that we calculated before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c36a0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=len(X.columns), figsize=(10, 5), sharex=False, sharey=True)\n",
    "\n",
    "\n",
    "ax.scatter(X, y)\n",
    "ax.set(xlabel='Molecular Weight')\n",
    "ax.set(ylabel=\"AC50\")\n",
    "# Optional: add a little padding so points on the edge arenâ€™t cut off\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e669d6d",
   "metadata": {},
   "source": [
    "## Train and Test Set\n",
    "We can obtain two sets when splitting the data by fingerprint similarity...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af7c374",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not IN_COLAB:\n",
    "    test_path = 'Example_Data/test.txt'\n",
    "    train_path = 'Example_Data/train.txt'\n",
    "else:\n",
    "    test_path = 'test.txt'\n",
    "    train_path = 'train.txt'\n",
    "with open(test_path, 'r') as test_file:\n",
    "    test_samples = test_file.read().splitlines()\n",
    "    test_samples = list(set(test_samples).intersection(set(considered_mols)))\n",
    "with open(train_path, 'r') as train_file:\n",
    "    train_samples = train_file.read().splitlines()\n",
    "    train_samples = list(set(train_samples).intersection(set(considered_mols)))\n",
    "X_train = X.loc[train_samples, :]\n",
    "y_train = y.loc[train_samples,:]\n",
    "X_test = X.loc[test_samples, :]\n",
    "y_test = y.loc[test_samples, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a56770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(20, 5), sharex='row', sharey=True)\n",
    "\n",
    "\n",
    "ax[0].scatter(X_train, y_train, label = 'Train set')\n",
    "ax[0].set(xlabel='Molecular Weight', ylabel = 'AC50')\n",
    "ax[1].scatter(X_test, y_test, label=\"Test set\")\n",
    "ax[1].set(xlabel='Molecular Weight')\n",
    "ax[0].set(title = 'Train set')\n",
    "ax[1].set(title = 'Test set')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096d7116",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "We fit on the training set and predict on the test set. For the fit, we use *least square regression*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b851cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression().fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e45b584",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Scatter points\n",
    "ax.scatter(X_train, y_train, label=\"Training points\")\n",
    "\n",
    "train_prediction = regressor.predict(X_train)\n",
    "# Regression line\n",
    "ax.plot(X_train, train_prediction, color=\"tab:orange\", lw=2.5)\n",
    "\n",
    "# Residuals: vertical segments from each point to the line at the same x\n",
    "for xi, yi, yhi in zip(X_train.values, y_train.values, train_prediction):\n",
    "    ax.vlines(xi, ymin=min(yi, yhi), ymax=max(yi, yhi),\n",
    "                color=\"gray\", linestyle=\"--\", lw=1.5)\n",
    "\n",
    "\n",
    "# Formatting\n",
    "ax.set_xlabel(\"Molecular Weight\")\n",
    "ax.set_ylabel(\"AC50\")\n",
    "title = \"Least Squares Illustration (vertical residuals)\"\n",
    "\n",
    "ax.set_title(title)\n",
    "ax.margins(x=0.05, y=0.1)\n",
    "ax.grid(True, alpha=0.2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c0fd1d",
   "metadata": {},
   "source": [
    "After fitting the regression line, we can use it to predict for any new data point in our test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265b48d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2,  figsize=(20,5), sharex='row', sharey=True)\n",
    "\n",
    "\n",
    "ax[0].scatter(X_train, y_train, label = 'Train set')\n",
    "ax[0].set(xlabel='Molecular Weight', ylabel = 'AC50')\n",
    "ax[0].plot(X_train,regressor.predict(X_train),linewidth=3,color=\"tab:orange\", label=\"Model predictions\")\n",
    "ax[1].scatter(X_test, y_test, label=\"Test set\")\n",
    "ax[1].set(xlabel='Molecular Weight')\n",
    "ax[1].plot(X_test, y_pred, linewidth=3, color=\"tab:orange\", label=\"Model predictions\")\n",
    "\n",
    "ax[0].set(title = 'Train set')\n",
    "ax[1].set(title = 'Test set')\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee9b559",
   "metadata": {},
   "source": [
    "From looking at this plot, we can guess that this model does not predict really well. To quantify how good/bad a model *performs*, we use performance metrics such as the mean absolute error (MAE), which tells us how much our prediction $\\hat{y}_i$ for a sample $i$ differs from the true value $y_i$ averaged over the number of samples $n$:\n",
    "\n",
    "$MAE = \\frac{1}{n} \\cdot \\sum_{i = 1}^{n}\\vert \\hat{y}_i - y_i\\vert$\n",
    "\n",
    "The value is in the same unit as the response (in our case the AC50). Thus, the judgement on whether the observed value is good or bad depends on the dataset. Another metric that is easier to interpret is the *coefficient of determination ($R^2$)*. It is a value in $(-\\inf, 1]$, which tells you whether your model was better ($>0$) or worse ($<0$) than simply predicting the mean $\\bar{y}$ of the test set.\n",
    "\n",
    "$R^2 = \\frac{\\sum_{i = 1}^{n} (\\hat{y}_i - y_i)^2}{\\sum_{i = 1}^{n} (\\bar{y} - y_i)^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0f642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean absolute error: {mean_absolute_error(y_test, y_pred):.2f}\")\n",
    "print(f\"Coefficient of determination: {r2_score(y_test, y_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8badfe4",
   "metadata": {},
   "source": [
    "The metrics reveal what we could already guess from our plot: The model does not perform well. Remember, however, that we only predict the AC50 based on the Molecular Weight. Thus, the next step is to include all 217 physicochemical descriptors to obtain better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07603f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_df['descriptors'] = smiles_df['molecule'].apply(Descriptors.CalcMolDescriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196afc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = smiles_df['descriptors'].apply(pd.Series)\n",
    "X.dropna(inplace=True)\n",
    "considered_mols = list(set(X.index).intersection(set(response_df.index)))\n",
    "train_samples = list(set(train_samples).intersection(set(considered_mols)))\n",
    "test_samples = list(set(test_samples).intersection(set(considered_mols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0748ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.loc[train_samples, :]\n",
    "y_train = y.loc[train_samples,:]\n",
    "X_test = X.loc[test_samples, :]\n",
    "y_test = y.loc[test_samples, :]\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "y_pred = linear_model.predict(X_test)\n",
    "print(f\"Mean absolute error: {mean_absolute_error(y_test, y_pred):.2f}\")\n",
    "print(f\"Coefficient of determination: {r2_score(y_test, y_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f69798b",
   "metadata": {},
   "source": [
    "As we can see, the model trained on all descriptors already performed better than the model only trained on Molecular Weight. However, the $R^2$ score is still below 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d150446",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
